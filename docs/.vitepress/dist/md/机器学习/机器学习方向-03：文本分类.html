<!DOCTYPE html>
<html lang="zh-CN" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>机器学习-03：文本分类任务 | 2024招新</title>
    <meta name="description" content="A VitePress site">
    <link rel="preload stylesheet" href="/glimmerRecruit/assets/style.691c4a08.css" as="style">
    
    <script type="module" src="/glimmerRecruit/assets/app.d79e5468.js"></script>
    <link rel="preload" href="/glimmerRecruit/assets/inter-roman-latin.2ed14f66.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/glimmerRecruit/assets/chunks/framework.ac9d47ba.js">
    <link rel="modulepreload" href="/glimmerRecruit/assets/chunks/theme.2e02a1e0.js">
    <link rel="modulepreload" href="/glimmerRecruit/assets/md_机器学习_机器学习方向-03：文本分类.md.73aa9c44.lean.js">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css" crossorigin="">
    <link rel="icon" href="/glimmerRecruit/image/favicon.png">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-5a346dfe><!--[--><!--]--><!--[--><span tabindex="-1" data-v-0f60ec36></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-0f60ec36> Skip to content </a><!--]--><!----><header class="VPNav" data-v-5a346dfe data-v-ae24b3ad><div class="VPNavBar has-sidebar" data-v-ae24b3ad data-v-a0fd61f4><div class="container" data-v-a0fd61f4><div class="title" data-v-a0fd61f4><div class="VPNavBarTitle has-sidebar" data-v-a0fd61f4 data-v-86d1bed8><a class="title" href="/glimmerRecruit/" data-v-86d1bed8><!--[--><!--]--><!--[--><img class="VPImage logo" src="/glimmerRecruit/image/favicon.png" alt data-v-8426fc1a><!--]--><!--[-->微光工作室<!--]--><!--[--><!--]--></a></div></div><div class="content" data-v-a0fd61f4><div class="curtain" data-v-a0fd61f4></div><div class="content-body" data-v-a0fd61f4><!--[--><!--]--><div class="VPNavBarSearch search" data-v-a0fd61f4><!----></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-a0fd61f4 data-v-7f418b0f><span id="main-nav-aria-label" class="visually-hidden" data-v-7f418b0f>Main Navigation</span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/glimmerRecruit/md/%E6%8B%9B%E6%96%B0%E8%AF%B4%E6%98%8E.html" tabindex="0" data-v-7f418b0f data-v-42ef59de><!--[--><span data-v-42ef59de>招新说明</span><!--]--></a><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-7f418b0f data-v-9c007e85><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-9c007e85><span class="text" data-v-9c007e85><!----><span data-v-9c007e85>日常基础</span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="text-icon" data-v-9c007e85><path d="M12,16c-0.3,0-0.5-0.1-0.7-0.3l-6-6c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l5.3,5.3l5.3-5.3c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-6,6C12.5,15.9,12.3,16,12,16z"></path></svg></span></button><div class="menu" data-v-9c007e85><div class="VPMenu" data-v-9c007e85 data-v-e7ea1737><div class="items" data-v-e7ea1737><!--[--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/glimmerRecruit/md/%E6%97%A5%E5%B8%B8%E5%9F%BA%E7%A1%80/%E6%97%A5%E5%B8%B8-01%EF%BC%9A%E4%BB%80%E4%B9%88%E6%98%AF%E8%AE%A1%E7%AE%97%E6%9C%BA%EF%BC%9F.html" data-v-43f1e123><!--[-->日常-01：什么是计算机？<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/glimmerRecruit/md/%E6%97%A5%E5%B8%B8%E5%9F%BA%E7%A1%80/%E6%97%A5%E5%B8%B8-02%EF%BC%9Amarkdown.html" data-v-43f1e123><!--[-->日常-02：markdown<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/glimmerRecruit/md/%E6%97%A5%E5%B8%B8%E5%9F%BA%E7%A1%80/%E6%97%A5%E5%B8%B8-03%EF%BC%9A%E6%95%B0%E6%8D%AE%E7%9A%84%E8%A1%A8%E7%A4%BA.html" data-v-43f1e123><!--[-->日常-03：数据的表示<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/glimmerRecruit/md/%E6%97%A5%E5%B8%B8%E5%9F%BA%E7%A1%80/%E6%97%A5%E5%B8%B8-04%EF%BC%9AIDE%E7%BC%96%E7%A8%8B%E5%89%8D%E7%9A%84%E5%87%86%E5%A4%87.html" data-v-43f1e123><!--[-->日常-04：IDE编程前的准备<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/glimmerRecruit/md/%E6%97%A5%E5%B8%B8%E5%9F%BA%E7%A1%80/%E6%97%A5%E5%B8%B8-05%EF%BC%9A%E4%BA%86%E8%A7%A3linux.html" data-v-43f1e123><!--[-->日常-05：了解linux<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/glimmerRecruit/md/%E6%97%A5%E5%B8%B8%E5%9F%BA%E7%A1%80/%E6%97%A5%E5%B8%B8-06%EF%BC%9A%E4%BB%A3%E7%A0%81%E7%AE%A1%E7%90%86.html" data-v-43f1e123><!--[-->日常-06：代码管理<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/glimmerRecruit/md/%E6%97%A5%E5%B8%B8%E5%9F%BA%E7%A1%80/%E6%97%A5%E5%B8%B8-07%EF%BC%9Aloafer%E6%83%B3%E6%89%93%E6%B4%BE(%E7%BD%91%E7%BB%9C).html" data-v-43f1e123><!--[-->日常-07：loafer想打派(网络)<!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-7f418b0f data-v-9c007e85><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-9c007e85><span class="text" data-v-9c007e85><!----><span data-v-9c007e85>C语言</span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="text-icon" data-v-9c007e85><path d="M12,16c-0.3,0-0.5-0.1-0.7-0.3l-6-6c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l5.3,5.3l5.3-5.3c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-6,6C12.5,15.9,12.3,16,12,16z"></path></svg></span></button><div class="menu" data-v-9c007e85><div class="VPMenu" data-v-9c007e85 data-v-e7ea1737><div class="items" data-v-e7ea1737><!--[--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/glimmerRecruit/md/C语言/" data-v-43f1e123><!--[-->C语言简介<!--]--></a></div><!--]--><!--[--><div class="VPMenuGroup" data-v-e7ea1737 data-v-69e747b5><p class="title" data-v-69e747b5>C基础</p><!--[--><!--[--><div class="VPMenuLink" data-v-69e747b5 data-v-43f1e123><a class="VPLink link" href="/glimmerRecruit/md/C%E8%AF%AD%E8%A8%80/C%20Basis-01%20Hello,world!.html" data-v-43f1e123><!--[-->C Basis-01 Hello,world!<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-69e747b5 data-v-43f1e123><a class="VPLink link" href="/glimmerRecruit/md/C%E8%AF%AD%E8%A8%80/C%20Basis-02%20%E6%9D%A5%E9%82%82%E9%80%85%E8%AF%AD%E5%8F%A5%E5%90%A7.html" data-v-43f1e123><!--[-->C Basis-02 来邂逅语句吧<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-69e747b5 data-v-43f1e123><a class="VPLink link" href="/glimmerRecruit/md/C%E8%AF%AD%E8%A8%80/C%20Basis-03%20%E7%A5%9E%E7%A7%98%E5%AF%86%E6%96%87.html" data-v-43f1e123><!--[-->C Basis-03 神秘密文<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-69e747b5 data-v-43f1e123><a class="VPLink link" href="/glimmerRecruit/md/C%E8%AF%AD%E8%A8%80/C%20Basis-04%20%E8%B5%A2%E4%B8%8D%E4%BA%86%E7%9A%84%E6%B8%B8%E6%88%8F.html" data-v-43f1e123><!--[-->C Basis-04 赢不了的游戏<!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-e7ea1737 data-v-69e747b5><p class="title" data-v-69e747b5>C项目</p><!--[--><!--[--><div class="VPMenuLink" data-v-69e747b5 data-v-43f1e123><a class="VPLink link" href="/glimmerRecruit/md/C%E8%AF%AD%E8%A8%80/C%20Project-%2000%20Manual.html" data-v-43f1e123><!--[-->C Project- 00 Manual<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-69e747b5 data-v-43f1e123><a class="VPLink link" href="/glimmerRecruit/md/C%E8%AF%AD%E8%A8%80/C%20Project-01%20%20Stack.html" data-v-43f1e123><!--[-->C Project-01  Stack<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-69e747b5 data-v-43f1e123><a class="VPLink link" href="/glimmerRecruit/md/C%E8%AF%AD%E8%A8%80/C%20project-02%20Management%20and%20Testing.html" data-v-43f1e123><!--[-->C project-02 Management and Testing<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-69e747b5 data-v-43f1e123><a class="VPLink link" href="/glimmerRecruit/md/C%E8%AF%AD%E8%A8%80/C%20project-03%20The%20Last.html" data-v-43f1e123><!--[-->C project-03 The Last<!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-e7ea1737 data-v-69e747b5><p class="title" data-v-69e747b5>C进阶</p><!--[--><!--[--><div class="VPMenuLink" data-v-69e747b5 data-v-43f1e123><a class="VPLink link" href="/glimmerRecruit/md/C%E8%AF%AD%E8%A8%80/C%20%E8%BF%9B%E9%98%B6-%E5%8A%A8%E6%80%81%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%99%A8.html" data-v-43f1e123><!--[-->C 进阶-动态内存分配器<!--]--></a></div><!--]--><!--]--></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-7f418b0f data-v-9c007e85><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-9c007e85><span class="text" data-v-9c007e85><!----><span data-v-9c007e85>前端</span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="text-icon" data-v-9c007e85><path d="M12,16c-0.3,0-0.5-0.1-0.7-0.3l-6-6c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l5.3,5.3l5.3-5.3c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-6,6C12.5,15.9,12.3,16,12,16z"></path></svg></span></button><div class="menu" data-v-9c007e85><div class="VPMenu" data-v-9c007e85 data-v-e7ea1737><div class="items" data-v-e7ea1737><!--[--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/glimmerRecruit/md/前端/" data-v-43f1e123><!--[-->前端简介<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/glimmerRecruit/md/%E5%89%8D%E7%AB%AF/T1-%E5%AF%BB%E6%89%BE%E5%BE%AE%E5%85%89%E5%A8%98-%E7%BD%91%E9%A1%B5html%E5%85%83%E7%B4%A0%E4%BF%AE%E6%94%B9.html" data-v-43f1e123><!--[-->T1-寻找微光娘-网页html元素修改<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/glimmerRecruit/md/%E5%89%8D%E7%AB%AF/T2-%E6%90%9C%E9%9B%86%E5%BE%AE%E5%85%89%E5%A8%98%E8%B6%B3%E8%BF%B9-%E7%BD%91%E7%AB%99%E5%9C%A8%E4%BD%A0%E7%94%B5%E8%84%91%E9%87%8C%E5%AD%98%E4%BA%86%E4%BB%80%E4%B9%88%E5%91%A2.html" data-v-43f1e123><!--[-->T2-搜集微光娘足迹-网站在你电脑里存了什么呢<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/glimmerRecruit/md/%E5%89%8D%E7%AB%AF/T3-%E5%BC%80%E8%BE%9F%E6%89%BE%E5%88%B0%E5%BE%AE%E5%85%89%E5%A8%98%E7%9A%84%E9%81%93%E8%B7%AF-CSS.html" data-v-43f1e123><!--[-->T3-开辟找到微光娘的道路-CSS<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/glimmerRecruit/md/%E5%89%8D%E7%AB%AF/%E5%89%8D%E7%AB%AF-04%20%E5%88%9D%E8%AF%86%E6%A1%86%E6%9E%B6.html" data-v-43f1e123><!--[-->前端-04 初识框架<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/glimmerRecruit/md/%E5%89%8D%E7%AB%AF/T5-%E6%80%BB%E7%AE%97%E8%A7%81%E5%88%B0%E4%BD%A0%E4%BA%86%EF%BC%8C%E5%BE%AE%E5%85%89%E5%A8%98%E2%80%94%E2%80%94%E5%88%B6%E4%BD%9Cblog.html" data-v-43f1e123><!--[-->T5-总算见到你了，微光娘——制作blog<!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-7f418b0f data-v-9c007e85><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-9c007e85><span class="text" data-v-9c007e85><!----><span data-v-9c007e85>后端</span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="text-icon" data-v-9c007e85><path d="M12,16c-0.3,0-0.5-0.1-0.7-0.3l-6-6c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l5.3,5.3l5.3-5.3c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-6,6C12.5,15.9,12.3,16,12,16z"></path></svg></span></button><div class="menu" data-v-9c007e85><div class="VPMenu" data-v-9c007e85 data-v-e7ea1737><div class="items" data-v-e7ea1737><!--[--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/glimmerRecruit/md/后端/" data-v-43f1e123><!--[-->后端简介<!--]--></a></div><!--]--><!--[--><div class="VPMenuGroup" data-v-e7ea1737 data-v-69e747b5><p class="title" data-v-69e747b5>JAVA</p><!--[--><!--[--><div class="VPMenuLink" data-v-69e747b5 data-v-43f1e123><a class="VPLink link" href="/glimmerRecruit/md/%E5%90%8E%E7%AB%AF/Java01.html" data-v-43f1e123><!--[-->Java-01：基础<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-69e747b5 data-v-43f1e123><a class="VPLink link" href="/glimmerRecruit/md/%E5%90%8E%E7%AB%AF/Java02.html" data-v-43f1e123><!--[-->Java-02：语言特性<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-69e747b5 data-v-43f1e123><a class="VPLink link" href="/glimmerRecruit/md/%E5%90%8E%E7%AB%AF/Java03.html" data-v-43f1e123><!--[-->Java-03：异常，网络<!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-e7ea1737 data-v-69e747b5><p class="title" data-v-69e747b5>GO</p><!--[--><!--[--><div class="VPMenuLink" data-v-69e747b5 data-v-43f1e123><a class="VPLink link" href="/glimmerRecruit/md/%E5%90%8E%E7%AB%AF/Go%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80-level0.html" data-v-43f1e123><!--[-->GO-01：level0<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-69e747b5 data-v-43f1e123><a class="VPLink link" href="/glimmerRecruit/md/%E5%90%8E%E7%AB%AF/Go%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80-level1.html" data-v-43f1e123><!--[-->GO-02：level1<!--]--></a></div><!--]--><!--]--></div><!--]--><!--[--><div class="VPMenuGroup" data-v-e7ea1737 data-v-69e747b5><p class="title" data-v-69e747b5>后端综合</p><!--[--><!--[--><div class="VPMenuLink" data-v-69e747b5 data-v-43f1e123><a class="VPLink link" href="/glimmerRecruit/md/%E5%90%8E%E7%AB%AF/%E5%90%8E%E7%AB%AF%E7%BB%BC%E5%90%88%E6%95%B0%E6%8D%AE%E5%BA%93%E5%87%BA%E9%A2%98.html" data-v-43f1e123><!--[-->综合项目-数据库<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-69e747b5 data-v-43f1e123><a class="VPLink link" href="/glimmerRecruit/md/%E5%90%8E%E7%AB%AF/%E5%90%8E%E7%AB%AF%E7%BB%BC%E5%90%88%E9%A1%B9%E7%9B%AE%E5%87%BA%E9%A2%98.html" data-v-43f1e123><!--[-->综合项目-项目实践<!--]--></a></div><!--]--><!--]--></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup active" data-v-7f418b0f data-v-9c007e85><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-9c007e85><span class="text" data-v-9c007e85><!----><span data-v-9c007e85>机器学习</span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="text-icon" data-v-9c007e85><path d="M12,16c-0.3,0-0.5-0.1-0.7-0.3l-6-6c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l5.3,5.3l5.3-5.3c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-6,6C12.5,15.9,12.3,16,12,16z"></path></svg></span></button><div class="menu" data-v-9c007e85><div class="VPMenu" data-v-9c007e85 data-v-e7ea1737><div class="items" data-v-e7ea1737><!--[--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/glimmerRecruit/md/机器学习/" data-v-43f1e123><!--[-->机器学习简介<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/glimmerRecruit/md/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%96%B9%E5%90%91-01%EF%BC%9A%E5%85%A5%E9%97%A8%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80.html" data-v-43f1e123><!--[-->机器学习方向-01：入门理论基础<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/glimmerRecruit/md/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%96%B9%E5%90%91-02%EF%BC%9A%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E5%AE%9E%E8%B7%B5.html" data-v-43f1e123><!--[-->机器学习方向-02：梯度下降实践<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link active" href="/glimmerRecruit/md/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%96%B9%E5%90%91-03%EF%BC%9A%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB.html" data-v-43f1e123><!--[-->机器学习方向-03：文本分类<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-e7ea1737 data-v-43f1e123><a class="VPLink link" href="/glimmerRecruit/md/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%96%B9%E5%90%91-04%EF%BC%9A%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8BGPT.html" data-v-43f1e123><!--[-->机器学习方向-04：大语言模型GPT<!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><a class="VPLink link vp-external-link-icon VPNavBarMenuLink" href="http://lab.glimmer.org.cn" target="_blank" rel="noreferrer" tabindex="0" data-v-7f418b0f data-v-42ef59de><!--[--><span data-v-42ef59de>光点计划</span><!--]--></a><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-a0fd61f4 data-v-e6aabb21><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title="toggle dark mode" aria-checked="false" data-v-e6aabb21 data-v-ce54a7d1 data-v-b1685198><span class="check" data-v-b1685198><span class="icon" data-v-b1685198><!--[--><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="sun" data-v-ce54a7d1><path d="M12,18c-3.3,0-6-2.7-6-6s2.7-6,6-6s6,2.7,6,6S15.3,18,12,18zM12,8c-2.2,0-4,1.8-4,4c0,2.2,1.8,4,4,4c2.2,0,4-1.8,4-4C16,9.8,14.2,8,12,8z"></path><path d="M12,4c-0.6,0-1-0.4-1-1V1c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,3.6,12.6,4,12,4z"></path><path d="M12,24c-0.6,0-1-0.4-1-1v-2c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,23.6,12.6,24,12,24z"></path><path d="M5.6,6.6c-0.3,0-0.5-0.1-0.7-0.3L3.5,4.9c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C6.2,6.5,5.9,6.6,5.6,6.6z"></path><path d="M19.8,20.8c-0.3,0-0.5-0.1-0.7-0.3l-1.4-1.4c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C20.3,20.7,20,20.8,19.8,20.8z"></path><path d="M3,13H1c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S3.6,13,3,13z"></path><path d="M23,13h-2c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S23.6,13,23,13z"></path><path d="M4.2,20.8c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C4.7,20.7,4.5,20.8,4.2,20.8z"></path><path d="M18.4,6.6c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C18.9,6.5,18.6,6.6,18.4,6.6z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="moon" data-v-ce54a7d1><path d="M12.1,22c-0.3,0-0.6,0-0.9,0c-5.5-0.5-9.5-5.4-9-10.9c0.4-4.8,4.2-8.6,9-9c0.4,0,0.8,0.2,1,0.5c0.2,0.3,0.2,0.8-0.1,1.1c-2,2.7-1.4,6.4,1.3,8.4c2.1,1.6,5,1.6,7.1,0c0.3-0.2,0.7-0.3,1.1-0.1c0.3,0.2,0.5,0.6,0.5,1c-0.2,2.7-1.5,5.1-3.6,6.8C16.6,21.2,14.4,22,12.1,22zM9.3,4.4c-2.9,1-5,3.6-5.2,6.8c-0.4,4.4,2.8,8.3,7.2,8.7c2.1,0.2,4.2-0.4,5.8-1.8c1.1-0.9,1.9-2.1,2.4-3.4c-2.5,0.9-5.3,0.5-7.5-1.1C9.2,11.4,8.1,7.7,9.3,4.4z"></path></svg><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-a0fd61f4 data-v-0394ad82 data-v-7bc22406><!--[--><a class="VPSocialLink no-icon" href="https://www.4399.com/" aria-label="github" target="_blank" rel="noopener" data-v-7bc22406 data-v-f80f8133><svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>GitHub</title><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-a0fd61f4 data-v-40855f84 data-v-9c007e85><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-9c007e85><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="icon" data-v-9c007e85><circle cx="12" cy="12" r="2"></circle><circle cx="19" cy="12" r="2"></circle><circle cx="5" cy="12" r="2"></circle></svg></button><div class="menu" data-v-9c007e85><div class="VPMenu" data-v-9c007e85 data-v-e7ea1737><!----><!--[--><!--[--><!----><div class="group" data-v-40855f84><div class="item appearance" data-v-40855f84><p class="label" data-v-40855f84>Appearance</p><div class="appearance-action" data-v-40855f84><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title="toggle dark mode" aria-checked="false" data-v-40855f84 data-v-ce54a7d1 data-v-b1685198><span class="check" data-v-b1685198><span class="icon" data-v-b1685198><!--[--><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="sun" data-v-ce54a7d1><path d="M12,18c-3.3,0-6-2.7-6-6s2.7-6,6-6s6,2.7,6,6S15.3,18,12,18zM12,8c-2.2,0-4,1.8-4,4c0,2.2,1.8,4,4,4c2.2,0,4-1.8,4-4C16,9.8,14.2,8,12,8z"></path><path d="M12,4c-0.6,0-1-0.4-1-1V1c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,3.6,12.6,4,12,4z"></path><path d="M12,24c-0.6,0-1-0.4-1-1v-2c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,23.6,12.6,24,12,24z"></path><path d="M5.6,6.6c-0.3,0-0.5-0.1-0.7-0.3L3.5,4.9c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C6.2,6.5,5.9,6.6,5.6,6.6z"></path><path d="M19.8,20.8c-0.3,0-0.5-0.1-0.7-0.3l-1.4-1.4c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C20.3,20.7,20,20.8,19.8,20.8z"></path><path d="M3,13H1c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S3.6,13,3,13z"></path><path d="M23,13h-2c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S23.6,13,23,13z"></path><path d="M4.2,20.8c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C4.7,20.7,4.5,20.8,4.2,20.8z"></path><path d="M18.4,6.6c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C18.9,6.5,18.6,6.6,18.4,6.6z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="moon" data-v-ce54a7d1><path d="M12.1,22c-0.3,0-0.6,0-0.9,0c-5.5-0.5-9.5-5.4-9-10.9c0.4-4.8,4.2-8.6,9-9c0.4,0,0.8,0.2,1,0.5c0.2,0.3,0.2,0.8-0.1,1.1c-2,2.7-1.4,6.4,1.3,8.4c2.1,1.6,5,1.6,7.1,0c0.3-0.2,0.7-0.3,1.1-0.1c0.3,0.2,0.5,0.6,0.5,1c-0.2,2.7-1.5,5.1-3.6,6.8C16.6,21.2,14.4,22,12.1,22zM9.3,4.4c-2.9,1-5,3.6-5.2,6.8c-0.4,4.4,2.8,8.3,7.2,8.7c2.1,0.2,4.2-0.4,5.8-1.8c1.1-0.9,1.9-2.1,2.4-3.4c-2.5,0.9-5.3,0.5-7.5-1.1C9.2,11.4,8.1,7.7,9.3,4.4z"></path></svg><!--]--></span></span></button></div></div></div><div class="group" data-v-40855f84><div class="item social-links" data-v-40855f84><div class="VPSocialLinks social-links-list" data-v-40855f84 data-v-7bc22406><!--[--><a class="VPSocialLink no-icon" href="https://www.4399.com/" aria-label="github" target="_blank" rel="noopener" data-v-7bc22406 data-v-f80f8133><svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>GitHub</title><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-a0fd61f4 data-v-e5dd9c1c><span class="container" data-v-e5dd9c1c><span class="top" data-v-e5dd9c1c></span><span class="middle" data-v-e5dd9c1c></span><span class="bottom" data-v-e5dd9c1c></span></span></button></div></div></div></div><!----></header><div class="VPLocalNav reached-top" data-v-5a346dfe data-v-79c8c1df><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-79c8c1df><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="menu-icon" data-v-79c8c1df><path d="M17,11H3c-0.6,0-1-0.4-1-1s0.4-1,1-1h14c0.6,0,1,0.4,1,1S17.6,11,17,11z"></path><path d="M21,7H3C2.4,7,2,6.6,2,6s0.4-1,1-1h18c0.6,0,1,0.4,1,1S21.6,7,21,7z"></path><path d="M21,15H3c-0.6,0-1-0.4-1-1s0.4-1,1-1h18c0.6,0,1,0.4,1,1S21.6,15,21,15z"></path><path d="M17,19H3c-0.6,0-1-0.4-1-1s0.4-1,1-1h14c0.6,0,1,0.4,1,1S17.6,19,17,19z"></path></svg><span class="menu-text" data-v-79c8c1df>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-79c8c1df data-v-1c15a60a><button data-v-1c15a60a>Return to top</button><!----></div></div><aside class="VPSidebar" data-v-5a346dfe data-v-b00e2fdd><div class="curtain" data-v-b00e2fdd></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-b00e2fdd><span class="visually-hidden" id="sidebar-aria-label" data-v-b00e2fdd> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="group" data-v-b00e2fdd><section class="VPSidebarItem level-0 is-link has-active" data-v-b00e2fdd data-v-e31bd47b><div class="item" tabindex="0" data-v-e31bd47b><div class="indicator" data-v-e31bd47b></div><a class="VPLink link link" href="/glimmerRecruit/md/机器学习/" data-v-e31bd47b><!--[--><h2 class="text" data-v-e31bd47b>机器学习</h2><!--]--></a><!----></div><div class="items" data-v-e31bd47b><!--[--><div class="VPSidebarItem level-1 is-link" data-v-e31bd47b data-v-e31bd47b><div class="item" data-v-e31bd47b><div class="indicator" data-v-e31bd47b></div><a class="VPLink link link" href="/glimmerRecruit/md/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%96%B9%E5%90%91-01%EF%BC%9A%E5%85%A5%E9%97%A8%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80.html" data-v-e31bd47b><!--[--><p class="text" data-v-e31bd47b>机器学习方向-01：入门理论基础</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-e31bd47b data-v-e31bd47b><div class="item" data-v-e31bd47b><div class="indicator" data-v-e31bd47b></div><a class="VPLink link link" href="/glimmerRecruit/md/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%96%B9%E5%90%91-02%EF%BC%9A%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E5%AE%9E%E8%B7%B5.html" data-v-e31bd47b><!--[--><p class="text" data-v-e31bd47b>机器学习方向-02：梯度下降实践</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-e31bd47b data-v-e31bd47b><div class="item" data-v-e31bd47b><div class="indicator" data-v-e31bd47b></div><a class="VPLink link link" href="/glimmerRecruit/md/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%96%B9%E5%90%91-03%EF%BC%9A%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB.html" data-v-e31bd47b><!--[--><p class="text" data-v-e31bd47b>机器学习方向-03：文本分类</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-e31bd47b data-v-e31bd47b><div class="item" data-v-e31bd47b><div class="indicator" data-v-e31bd47b></div><a class="VPLink link link" href="/glimmerRecruit/md/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%96%B9%E5%90%91-04%EF%BC%9A%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8BGPT.html" data-v-e31bd47b><!--[--><p class="text" data-v-e31bd47b>机器学习方向-04：大语言模型GPT</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-5a346dfe data-v-669faec9><div class="VPDoc has-sidebar has-aside" data-v-669faec9 data-v-6b87e69f><!--[--><!--]--><div class="container" data-v-6b87e69f><div class="aside" data-v-6b87e69f><div class="aside-curtain" data-v-6b87e69f></div><div class="aside-container" data-v-6b87e69f><div class="aside-content" data-v-6b87e69f><div class="VPDocAside" data-v-6b87e69f data-v-3f215769><!--[--><!--]--><!--[--><!--]--><div class="VPDocAsideOutline" role="navigation" data-v-3f215769 data-v-d330b1bb><div class="content" data-v-d330b1bb><div class="outline-marker" data-v-d330b1bb></div><div class="outline-title" role="heading" aria-level="2" data-v-d330b1bb>On this page</div><nav aria-labelledby="doc-outline-aria-label" data-v-d330b1bb><span class="visually-hidden" id="doc-outline-aria-label" data-v-d330b1bb> Table of Contents for current page </span><ul class="root" data-v-d330b1bb data-v-d0ee3533><!--[--><!--]--></ul></nav></div></div><!--[--><!--]--><div class="spacer" data-v-3f215769></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-6b87e69f><div class="content-container" data-v-6b87e69f><!--[--><!--]--><!----><main class="main" data-v-6b87e69f><div style="position:relative;" class="vp-doc _glimmerRecruit_md_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%96%B9%E5%90%91-03%EF%BC%9A%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB" data-v-6b87e69f><div><p><img src="https://img1.imgtp.com/2024/09/10/081jz2kT.PNG" alt=""></p><h1 id="机器学习-03-文本分类任务" tabindex="-1"><strong>机器学习</strong>-03：文本分类任务 <a class="header-anchor" href="#机器学习-03-文本分类任务" aria-label="Permalink to &quot;**机器学习**-03：文本分类任务&quot;">​</a></h1><blockquote><p><code>难度系数</code>：中等</p><p>在学习了有关梯度下降的知识之后，可以开始尝试深度学习框架了！深度学习框架是用于构建、训练和部署深度学习模型的软件工具。它们提供了一系列的函数、类和工具，使得开发者可以方便地定义、优化和执行深度学习模型。常见的深度学习框架有tensorflow、pytorch、keras等，选择一种框架进行学习，在学习过程中记录下你的思考与体验。</p></blockquote><h2 id="前置知识" tabindex="-1">前置知识 <a class="header-anchor" href="#前置知识" aria-label="Permalink to &quot;前置知识&quot;">​</a></h2><h3 id="nlp前置知识" tabindex="-1">NLP前置知识 <a class="header-anchor" href="#nlp前置知识" aria-label="Permalink to &quot;NLP前置知识&quot;">​</a></h3><p>在理解和应用 RNN 类模型进行文本分类之前，有几个重要的 NLP 前置知识需要了解：</p><blockquote><p><strong>文本分类：</strong> 文本分类是一种自然语言处理（NLP）任务，旨在将给定的文本分配到预定义的类别或标签中。它是根据文本的内容和语义特征来判断文本所属类别的过程。在文本分类任务中，通常有一个已知的类别集合，每个类别代表一个特定的主题、情感或类别。模型的目标是根据文本的特征和上下文信息，将其正确地分类到相应的类别中。</p><p><strong>文本预处理：</strong> 包括文本清洗、分词、去除停用词等，以便将文本数据转化为可供模型处理的形式。</p><p><strong>词嵌入</strong>（Word Embeddings）：将文本中的单词映射为低维的实数向量表示，以捕捉单词之间的语义关系。</p><p><strong>循环神经网络</strong>（Recurrent Neural Networks，RNN）：一种能够处理序列数据的神经网络模型，通过在每个时间步骤上传递隐藏状态，可以捕捉到序列中的上下文信息。</p><p><strong>长短时记忆网络</strong>（Long Short-Term Memory，LSTM）：一种RNN的变体，通过引入门控机制，可以更好地处理长期依赖关系。</p><p><strong>注意⭐️：在本次任务中，我们并不限定任何模型和实现方式。RNN和LSTM不是必须的，推荐使用，还未接触RNN的初学者同学也可以使用MLP模型（是的MLP也是可以用的，只是效果差点，但是我们强烈推荐初学者同学用MLP来一次实践），高阶的同学甚至可以直接上BERT模型</strong></p></blockquote><h3 id="文本处理前置知识" tabindex="-1">文本处理前置知识 <a class="header-anchor" href="#文本处理前置知识" aria-label="Permalink to &quot;文本处理前置知识&quot;">​</a></h3><p>文本处理是指对文本数据进行<strong>预处理和转换</strong>的过程，以便于后续的文本分析、挖掘和建模。文本处理的目标是清洗、规范和转换原始文本数据，以提取有用的信息和特征，从而支持各种文本相关的任务，如文本分类、情感分析、机器翻译等。</p><p>下面是一些常见的文本处理步骤：</p><ol><li>文本清洗：去除文本中的特殊字符、标点符号和HTML标签等无关信息。处理大小写，可以将文本转换为小写形式，以避免同一个单词因大小写不同而被视为不同的词汇。</li></ol><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#F97583;">import</span><span style="color:#E1E4E8;"> re</span></span>
<span class="line"><span style="color:#F97583;">def</span><span style="color:#E1E4E8;"> </span><span style="color:#B392F0;">clean_text</span><span style="color:#E1E4E8;">(text):</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># 去除特殊字符和标点符号</span></span>
<span class="line"><span style="color:#E1E4E8;">    text </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> re.sub(</span><span style="color:#F97583;">r</span><span style="color:#9ECBFF;">&quot;</span><span style="color:#79B8FF;">[</span><span style="color:#F97583;">^</span><span style="color:#79B8FF;">a-zA-Z0-9]</span><span style="color:#9ECBFF;">&quot;</span><span style="color:#E1E4E8;">, </span><span style="color:#9ECBFF;">&quot; &quot;</span><span style="color:#E1E4E8;">, text)</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># 将文本转换为小写</span></span>
<span class="line"><span style="color:#E1E4E8;">    text </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> text.lower()</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># 去除多余的空格</span></span>
<span class="line"><span style="color:#E1E4E8;">    text </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> re.sub(</span><span style="color:#F97583;">r</span><span style="color:#9ECBFF;">&quot;</span><span style="color:#79B8FF;">\s</span><span style="color:#F97583;">+</span><span style="color:#9ECBFF;">&quot;</span><span style="color:#E1E4E8;">, </span><span style="color:#9ECBFF;">&quot; &quot;</span><span style="color:#E1E4E8;">, text)</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#F97583;">return</span><span style="color:#E1E4E8;"> text</span></span>
<span class="line"><span style="color:#6A737D;"># 示例文本</span></span>
<span class="line"><span style="color:#E1E4E8;">text </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">&quot;Hello, this is an example text! It contains special characters and punctuation.&quot;</span></span>
<span class="line"><span style="color:#6A737D;"># 清洗文本</span></span>
<span class="line"><span style="color:#E1E4E8;">cleaned_text </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> clean_text(text)</span></span>
<span class="line"><span style="color:#79B8FF;">print</span><span style="color:#E1E4E8;">(cleaned_text)</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> re</span></span>
<span class="line"><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">clean_text</span><span style="color:#24292E;">(text):</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># 去除特殊字符和标点符号</span></span>
<span class="line"><span style="color:#24292E;">    text </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> re.sub(</span><span style="color:#D73A49;">r</span><span style="color:#032F62;">&quot;</span><span style="color:#005CC5;">[</span><span style="color:#D73A49;">^</span><span style="color:#005CC5;">a-zA-Z0-9]</span><span style="color:#032F62;">&quot;</span><span style="color:#24292E;">, </span><span style="color:#032F62;">&quot; &quot;</span><span style="color:#24292E;">, text)</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># 将文本转换为小写</span></span>
<span class="line"><span style="color:#24292E;">    text </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> text.lower()</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># 去除多余的空格</span></span>
<span class="line"><span style="color:#24292E;">    text </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> re.sub(</span><span style="color:#D73A49;">r</span><span style="color:#032F62;">&quot;</span><span style="color:#005CC5;">\s</span><span style="color:#D73A49;">+</span><span style="color:#032F62;">&quot;</span><span style="color:#24292E;">, </span><span style="color:#032F62;">&quot; &quot;</span><span style="color:#24292E;">, text)</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">return</span><span style="color:#24292E;"> text</span></span>
<span class="line"><span style="color:#6A737D;"># 示例文本</span></span>
<span class="line"><span style="color:#24292E;">text </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&quot;Hello, this is an example text! It contains special characters and punctuation.&quot;</span></span>
<span class="line"><span style="color:#6A737D;"># 清洗文本</span></span>
<span class="line"><span style="color:#24292E;">cleaned_text </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> clean_text(text)</span></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;">(cleaned_text)</span></span></code></pre></div><p>在以上代码中，<code>clean_text</code>函数使用正则表达式去除了特殊字符和标点符号，将文本转换为小写，并去除了多余的空格。你可以根据需要进行修改和扩展，例如添加停用词移除、词干提取等其他文本清洗步骤。</p><ol start="2"><li>分词（Tokenization）：将文本分割成单词或子词的序列。</li></ol><div class="language-Python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">Python</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#F97583;">import</span><span style="color:#E1E4E8;"> re</span></span>
<span class="line"><span style="color:#F97583;">def</span><span style="color:#E1E4E8;"> </span><span style="color:#B392F0;">tokenize</span><span style="color:#E1E4E8;">(text):</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># 将文本中的标点符号替换为空格</span></span>
<span class="line"><span style="color:#E1E4E8;">    text </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> re.sub(</span><span style="color:#F97583;">r</span><span style="color:#9ECBFF;">&#39;</span><span style="color:#79B8FF;">[</span><span style="color:#F97583;">^</span><span style="color:#79B8FF;">\w\s]</span><span style="color:#9ECBFF;">&#39;</span><span style="color:#E1E4E8;">, </span><span style="color:#9ECBFF;">&#39; &#39;</span><span style="color:#E1E4E8;">, text)</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># 将文本按空格分割成单词列表</span></span>
<span class="line"><span style="color:#E1E4E8;">    tokens </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> text.split()</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#F97583;">return</span><span style="color:#E1E4E8;"> tokens</span></span>
<span class="line"><span style="color:#6A737D;"># 示例文本</span></span>
<span class="line"><span style="color:#E1E4E8;">text </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">&quot;This is an example sentence for tokenization.&quot;</span></span>
<span class="line"><span style="color:#6A737D;"># 分词</span></span>
<span class="line"><span style="color:#E1E4E8;">tokens </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> tokenize(text)</span></span>
<span class="line"><span style="color:#79B8FF;">print</span><span style="color:#E1E4E8;">(tokens)</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> re</span></span>
<span class="line"><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">tokenize</span><span style="color:#24292E;">(text):</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># 将文本中的标点符号替换为空格</span></span>
<span class="line"><span style="color:#24292E;">    text </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> re.sub(</span><span style="color:#D73A49;">r</span><span style="color:#032F62;">&#39;</span><span style="color:#005CC5;">[</span><span style="color:#D73A49;">^</span><span style="color:#005CC5;">\w\s]</span><span style="color:#032F62;">&#39;</span><span style="color:#24292E;">, </span><span style="color:#032F62;">&#39; &#39;</span><span style="color:#24292E;">, text)</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># 将文本按空格分割成单词列表</span></span>
<span class="line"><span style="color:#24292E;">    tokens </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> text.split()</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">return</span><span style="color:#24292E;"> tokens</span></span>
<span class="line"><span style="color:#6A737D;"># 示例文本</span></span>
<span class="line"><span style="color:#24292E;">text </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&quot;This is an example sentence for tokenization.&quot;</span></span>
<span class="line"><span style="color:#6A737D;"># 分词</span></span>
<span class="line"><span style="color:#24292E;">tokens </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> tokenize(text)</span></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;">(tokens)</span></span></code></pre></div><ol start="3"><li>去除停用词（Stop Words）：停用词是在文本中频繁出现但通常不携带重要信息的常见词汇，如介词、连词和冠词等。去除停用词可以减少文本的维度，并提高模型的效果。</li></ol><div class="language-Python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">Python</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#6A737D;"># 停用词列表</span></span>
<span class="line"><span style="color:#E1E4E8;">stop_words </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> [</span><span style="color:#9ECBFF;">&quot;the&quot;</span><span style="color:#E1E4E8;">, </span><span style="color:#9ECBFF;">&quot;is&quot;</span><span style="color:#E1E4E8;">, </span><span style="color:#9ECBFF;">&quot;an&quot;</span><span style="color:#E1E4E8;">, </span><span style="color:#9ECBFF;">&quot;of&quot;</span><span style="color:#E1E4E8;">]</span></span>
<span class="line"><span style="color:#6A737D;"># 示例文本</span></span>
<span class="line"><span style="color:#E1E4E8;">text </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">&quot;This is an example sentence demonstrating the removal of stopwords.&quot;</span></span>
<span class="line"><span style="color:#6A737D;"># 分词</span></span>
<span class="line"><span style="color:#E1E4E8;">tokens </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> text.split()</span></span>
<span class="line"><span style="color:#6A737D;"># 去除停用词</span></span>
<span class="line"><span style="color:#E1E4E8;">filtered_tokens </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> [word </span><span style="color:#F97583;">for</span><span style="color:#E1E4E8;"> word </span><span style="color:#F97583;">in</span><span style="color:#E1E4E8;"> tokens </span><span style="color:#F97583;">if</span><span style="color:#E1E4E8;"> word.lower() </span><span style="color:#F97583;">not</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">in</span><span style="color:#E1E4E8;"> stop_words]</span></span>
<span class="line"><span style="color:#6A737D;"># 打印结果</span></span>
<span class="line"><span style="color:#79B8FF;">print</span><span style="color:#E1E4E8;">(</span><span style="color:#9ECBFF;">&quot;Original Text:&quot;</span><span style="color:#E1E4E8;">)</span></span>
<span class="line"><span style="color:#79B8FF;">print</span><span style="color:#E1E4E8;">(text)</span></span>
<span class="line"><span style="color:#79B8FF;">print</span><span style="color:#E1E4E8;">()</span></span>
<span class="line"><span style="color:#79B8FF;">print</span><span style="color:#E1E4E8;">(</span><span style="color:#9ECBFF;">&quot;Filtered Text:&quot;</span><span style="color:#E1E4E8;">)</span></span>
<span class="line"><span style="color:#79B8FF;">print</span><span style="color:#E1E4E8;">(</span><span style="color:#9ECBFF;">&#39; &#39;</span><span style="color:#E1E4E8;">.join(filtered_tokens))</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#6A737D;"># 停用词列表</span></span>
<span class="line"><span style="color:#24292E;">stop_words </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> [</span><span style="color:#032F62;">&quot;the&quot;</span><span style="color:#24292E;">, </span><span style="color:#032F62;">&quot;is&quot;</span><span style="color:#24292E;">, </span><span style="color:#032F62;">&quot;an&quot;</span><span style="color:#24292E;">, </span><span style="color:#032F62;">&quot;of&quot;</span><span style="color:#24292E;">]</span></span>
<span class="line"><span style="color:#6A737D;"># 示例文本</span></span>
<span class="line"><span style="color:#24292E;">text </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&quot;This is an example sentence demonstrating the removal of stopwords.&quot;</span></span>
<span class="line"><span style="color:#6A737D;"># 分词</span></span>
<span class="line"><span style="color:#24292E;">tokens </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> text.split()</span></span>
<span class="line"><span style="color:#6A737D;"># 去除停用词</span></span>
<span class="line"><span style="color:#24292E;">filtered_tokens </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> [word </span><span style="color:#D73A49;">for</span><span style="color:#24292E;"> word </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> tokens </span><span style="color:#D73A49;">if</span><span style="color:#24292E;"> word.lower() </span><span style="color:#D73A49;">not</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> stop_words]</span></span>
<span class="line"><span style="color:#6A737D;"># 打印结果</span></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;">(</span><span style="color:#032F62;">&quot;Original Text:&quot;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;">(text)</span></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;">()</span></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;">(</span><span style="color:#032F62;">&quot;Filtered Text:&quot;</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;">(</span><span style="color:#032F62;">&#39; &#39;</span><span style="color:#24292E;">.join(filtered_tokens))</span></span></code></pre></div><p>在上述代码中，首先定义了一个停用词列（<code>stop_words</code>），其中包含要去除的常见停用词。定义了一个示例文本（<code>text</code>）。接下来，使用<code>split()</code>方法将文本分割成单词，得到一个单词列表（<code>tokens</code>）。然后，使用列表推导式，遍历分词后的单词列表，并将不在停用词列表中的单词保留下来（使用<code>lower()</code>方法将单词转换为小写进行比较）。最后，使用<code>join()</code>方法将过滤后的单词列表重新组合成一个字符串，并打印结果。</p><p><strong>注意：</strong> 上述代码均为示例，与本题无关，实际在完成本题过程中，需要根据具体任务和数据进行相应的调整和修改。</p><h2 id="题目-情绪分类" tabindex="-1">题目-情绪分类 <a class="header-anchor" href="#题目-情绪分类" aria-label="Permalink to &quot;题目-情绪分类&quot;">​</a></h2><ul><li>本题旨在训练一个文本二分类模型，用以预测每个句子所表达的情绪是正面还是负面</li><li>可以使用 MLP 或者 RNN 类模型等，不强制使用任何模型或实现方法，自由发挥！</li><li>可使用深度学习框架，框架不限，推荐使用 tensorflow2 或 pytorch</li></ul><h2 id="举个栗子🌰" tabindex="-1">举个栗子🌰 <a class="header-anchor" href="#举个栗子🌰" aria-label="Permalink to &quot;举个栗子🌰&quot;">​</a></h2><p><strong>下面是一个使用</strong> <strong>pytorch</strong> <strong>框架+ LSTM 模型的代码示例</strong></p><h3 id="环境配置" tabindex="-1"><strong>环境配置</strong> <a class="header-anchor" href="#环境配置" aria-label="Permalink to &quot;**环境配置**&quot;">​</a></h3><ol><li>安装 Anaconda,学习简单的 conda 命令</li><li>推荐选择 tensorflow 或者 pytorch 框架，则创建相应环境，安装 tensorflow/pytorch，以及 GPU 配置（建议安装，需要电脑有独显）</li></ol><h3 id="数据处理" tabindex="-1"><strong>数据处理</strong> <a class="header-anchor" href="#数据处理" aria-label="Permalink to &quot;**数据处理**&quot;">​</a></h3><ul><li>获取数据集（招新群 683234808）或者从 kaggle 上下载 <a href="https://www.kaggle.com/competitions/ml2020spring-hw4/overview" target="_blank" rel="noreferrer">ML2020spring - hw4 | Kaggle</a></li><li><strong>在该数据集中只会用到 training_label.txt，并且请自行划分训练、验证、测试集</strong></li><li>训练集的每一行为一个数据，每个数据分别包含一个文本和一个 label（0表示消极情绪，1表示积极情绪）</li><li>拿到数据之后，需要对数据进行文本处理（可参考上文），再建立词表，以及做 word2id、label2id 的映射等：</li></ul><div class="language-Python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">Python</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#F97583;">def</span><span style="color:#E1E4E8;"> </span><span style="color:#B392F0;">create_corpus</span><span style="color:#E1E4E8;">(texts):</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#9ECBFF;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#9ECBFF;">    通过对训练文本做文本处理（参考上文）并统计分词结果，建立词表</span></span>
<span class="line"><span style="color:#9ECBFF;">    小Tips：建立词表的时候别忘了加一些特殊token，如：</span></span>
<span class="line"><span style="color:#9ECBFF;">        [PAD]：用于id序列的padding的token</span></span>
<span class="line"><span style="color:#9ECBFF;">        [UNK]：用于映射不存在于词表的词</span></span>
<span class="line"><span style="color:#9ECBFF;">    请自行实现</span></span>
<span class="line"><span style="color:#9ECBFF;">    &quot;&quot;&quot;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F97583;">def</span><span style="color:#E1E4E8;"> </span><span style="color:#B392F0;">preprocess_text</span><span style="color:#E1E4E8;">(text):</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#9ECBFF;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#9ECBFF;">    对数据进行处理，包括文本处理（参考上文）、做word2id映射、id序列的padding等</span></span>
<span class="line"><span style="color:#9ECBFF;">    padding：</span></span>
<span class="line"><span style="color:#9ECBFF;">        由于将不同的文本序列组成一个batch时，需要每个文本的长度相同</span></span>
<span class="line"><span style="color:#9ECBFF;">        所以需要对某些文本进行截断或填充，填充的word即为[PAD]</span></span>
<span class="line"><span style="color:#9ECBFF;">        如：将I love you填充至seq_len=5，即为I love you [PAD] [PAD]</span></span>
<span class="line"><span style="color:#9ECBFF;">    请自行实现</span></span>
<span class="line"><span style="color:#9ECBFF;">    &quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span></span>
<span class="line"><span style="color:#F97583;">def</span><span style="color:#E1E4E8;"> </span><span style="color:#B392F0;">preprocess_label</span><span style="color:#E1E4E8;">(label):</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#9ECBFF;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#9ECBFF;">    包括label2id的映射等</span></span>
<span class="line"><span style="color:#9ECBFF;">    请自行实现</span></span>
<span class="line"><span style="color:#9ECBFF;">    &quot;&quot;&quot;</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">create_corpus</span><span style="color:#24292E;">(texts):</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#032F62;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#032F62;">    通过对训练文本做文本处理（参考上文）并统计分词结果，建立词表</span></span>
<span class="line"><span style="color:#032F62;">    小Tips：建立词表的时候别忘了加一些特殊token，如：</span></span>
<span class="line"><span style="color:#032F62;">        [PAD]：用于id序列的padding的token</span></span>
<span class="line"><span style="color:#032F62;">        [UNK]：用于映射不存在于词表的词</span></span>
<span class="line"><span style="color:#032F62;">    请自行实现</span></span>
<span class="line"><span style="color:#032F62;">    &quot;&quot;&quot;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">preprocess_text</span><span style="color:#24292E;">(text):</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#032F62;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#032F62;">    对数据进行处理，包括文本处理（参考上文）、做word2id映射、id序列的padding等</span></span>
<span class="line"><span style="color:#032F62;">    padding：</span></span>
<span class="line"><span style="color:#032F62;">        由于将不同的文本序列组成一个batch时，需要每个文本的长度相同</span></span>
<span class="line"><span style="color:#032F62;">        所以需要对某些文本进行截断或填充，填充的word即为[PAD]</span></span>
<span class="line"><span style="color:#032F62;">        如：将I love you填充至seq_len=5，即为I love you [PAD] [PAD]</span></span>
<span class="line"><span style="color:#032F62;">    请自行实现</span></span>
<span class="line"><span style="color:#032F62;">    &quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#24292E;">    </span></span>
<span class="line"><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">preprocess_label</span><span style="color:#24292E;">(label):</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#032F62;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#032F62;">    包括label2id的映射等</span></span>
<span class="line"><span style="color:#032F62;">    请自行实现</span></span>
<span class="line"><span style="color:#032F62;">    &quot;&quot;&quot;</span></span></code></pre></div><h3 id="dataset" tabindex="-1"><strong>Dataset</strong> <a class="header-anchor" href="#dataset" aria-label="Permalink to &quot;**Dataset**&quot;">​</a></h3><ul><li>在pytorch中，需要建立<code>Dataset()</code>定义我们处理数据的方式，其中的<code>__getitem()__</code>即定义了每单个数据的处理方法，之后在训练时再用<code>DataLoader()</code>进行封装，即可组成一个 batch 的数据</li></ul><div class="language-Python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">Python</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#F97583;">class</span><span style="color:#E1E4E8;"> </span><span style="color:#B392F0;">CustomDataset</span><span style="color:#E1E4E8;">(</span><span style="color:#B392F0;">torch</span><span style="color:#E1E4E8;">.</span><span style="color:#B392F0;">utils</span><span style="color:#E1E4E8;">.</span><span style="color:#B392F0;">data</span><span style="color:#E1E4E8;">.</span><span style="color:#B392F0;">Dataset</span><span style="color:#E1E4E8;">):</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#F97583;">def</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">__init__</span><span style="color:#E1E4E8;">(self, texts, labels):</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.texts </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> texts</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.labels </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> labels</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#F97583;">def</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">__getitem__</span><span style="color:#E1E4E8;">(self, index):</span></span>
<span class="line"><span style="color:#E1E4E8;">        text </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> preprocess_text(</span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.texts[index])</span></span>
<span class="line"><span style="color:#E1E4E8;">        label </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> preprocess_label(</span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.labels[index])</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#F97583;">return</span><span style="color:#E1E4E8;"> text, label</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#F97583;">def</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">__len__</span><span style="color:#E1E4E8;">(self):</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#F97583;">return</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">len</span><span style="color:#E1E4E8;">(</span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.texts)</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#D73A49;">class</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">CustomDataset</span><span style="color:#24292E;">(</span><span style="color:#6F42C1;">torch</span><span style="color:#24292E;">.</span><span style="color:#6F42C1;">utils</span><span style="color:#24292E;">.</span><span style="color:#6F42C1;">data</span><span style="color:#24292E;">.</span><span style="color:#6F42C1;">Dataset</span><span style="color:#24292E;">):</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">__init__</span><span style="color:#24292E;">(self, texts, labels):</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.texts </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> texts</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.labels </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> labels</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">__getitem__</span><span style="color:#24292E;">(self, index):</span></span>
<span class="line"><span style="color:#24292E;">        text </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> preprocess_text(</span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.texts[index])</span></span>
<span class="line"><span style="color:#24292E;">        label </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> preprocess_label(</span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.labels[index])</span></span>
<span class="line"><span style="color:#24292E;">        </span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">return</span><span style="color:#24292E;"> text, label</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">__len__</span><span style="color:#24292E;">(self):</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">return</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">len</span><span style="color:#24292E;">(</span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.texts)</span></span></code></pre></div><h3 id="构造模型" tabindex="-1"><strong>构造模型</strong> <a class="header-anchor" href="#构造模型" aria-label="Permalink to &quot;**构造模型**&quot;">​</a></h3><ul><li>接下来就是如何搭建模型，这里使用 LSTM 做实例，大家也可以尽情尝试其他模型</li><li>❗<strong>请一定保证你使用的模型是你会的，比如如果你用了 LSTM，那么我们则会在面试时抽查 LSTM 相关的知识</strong>❗</li><li>文本任务都会涉及到 embedding，其本质是存储了一个向量矩阵，该矩阵<code>shape=(vocab_size, embedding_dim)</code>，在前向传播时，会将每个词都映射为一个 embedding_dim 维的向量</li></ul><div class="language-Python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">Python</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#F97583;">class</span><span style="color:#E1E4E8;"> </span><span style="color:#B392F0;">LSTMModel</span><span style="color:#E1E4E8;">(</span><span style="color:#B392F0;">torch</span><span style="color:#E1E4E8;">.</span><span style="color:#B392F0;">nn</span><span style="color:#E1E4E8;">.</span><span style="color:#B392F0;">Module</span><span style="color:#E1E4E8;">):</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#F97583;">def</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">__init__</span><span style="color:#E1E4E8;">(self, vocab_size, embedding_dim, hidden_dim, num_layers, dropout</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">0.1</span><span style="color:#E1E4E8;">):</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">super</span><span style="color:#E1E4E8;">(LSTMModel, </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">).</span><span style="color:#79B8FF;">__init__</span><span style="color:#E1E4E8;">()</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#6A737D;"># embedding是将某个词对应的id映射到向量，然后用这个向量作为模型的输入，该向量的维度为embedding_dim</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.embedding </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> torch.nn.Embedding(vocab_size, embedding_dim)</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#6A737D;"># 这里用的LSTM模型，也可以尝试其他模型</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.</span><span style="color:#79B8FF;">LSTM</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> torch.nn.LSTM(embedding_dim, hidden_dim, </span><span style="color:#FFAB70;">num_layers</span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;">num_layers, </span><span style="color:#FFAB70;">batch_first</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">True</span><span style="color:#E1E4E8;">)</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.classifier </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> torch.nn.Sequential(</span></span>
<span class="line"><span style="color:#E1E4E8;">            torch.nn.Dropout(dropout),</span></span>
<span class="line"><span style="color:#E1E4E8;">            torch.nn.Linear(hidden_dim, </span><span style="color:#79B8FF;">2</span><span style="color:#E1E4E8;">)</span></span>
<span class="line"><span style="color:#E1E4E8;">        )</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#F97583;">def</span><span style="color:#E1E4E8;"> </span><span style="color:#B392F0;">forward</span><span style="color:#E1E4E8;">(self, inputs):</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#6A737D;"># 最开始的输入inputs.shape = (batch_size, seq_len)</span></span>
<span class="line"><span style="color:#E1E4E8;">        inputs </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.embedding(inputs)</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#6A737D;"># 过了self.embdding之后，inputs.shape = (batch_size, seq_len, embedding_dim)</span></span>
<span class="line"><span style="color:#E1E4E8;">        x, _ </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.LSTM(inputs)</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#6A737D;"># x.shape = (batch_size, seq_len, hidden_size)</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#6A737D;"># 取用 LSTM 最后一个的 hidden state</span></span>
<span class="line"><span style="color:#E1E4E8;">        x </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> x[:, </span><span style="color:#F97583;">-</span><span style="color:#79B8FF;">1</span><span style="color:#E1E4E8;">, :]</span></span>
<span class="line"><span style="color:#E1E4E8;">        x </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.classifier(x)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#F97583;">return</span><span style="color:#E1E4E8;"> x</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#D73A49;">class</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">LSTMModel</span><span style="color:#24292E;">(</span><span style="color:#6F42C1;">torch</span><span style="color:#24292E;">.</span><span style="color:#6F42C1;">nn</span><span style="color:#24292E;">.</span><span style="color:#6F42C1;">Module</span><span style="color:#24292E;">):</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">__init__</span><span style="color:#24292E;">(self, vocab_size, embedding_dim, hidden_dim, num_layers, dropout</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">0.1</span><span style="color:#24292E;">):</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">super</span><span style="color:#24292E;">(LSTMModel, </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">).</span><span style="color:#005CC5;">__init__</span><span style="color:#24292E;">()</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># embedding是将某个词对应的id映射到向量，然后用这个向量作为模型的输入，该向量的维度为embedding_dim</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.embedding </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> torch.nn.Embedding(vocab_size, embedding_dim)</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># 这里用的LSTM模型，也可以尝试其他模型</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.</span><span style="color:#005CC5;">LSTM</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> torch.nn.LSTM(embedding_dim, hidden_dim, </span><span style="color:#E36209;">num_layers</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">num_layers, </span><span style="color:#E36209;">batch_first</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">True</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.classifier </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> torch.nn.Sequential(</span></span>
<span class="line"><span style="color:#24292E;">            torch.nn.Dropout(dropout),</span></span>
<span class="line"><span style="color:#24292E;">            torch.nn.Linear(hidden_dim, </span><span style="color:#005CC5;">2</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">        )</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">forward</span><span style="color:#24292E;">(self, inputs):</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># 最开始的输入inputs.shape = (batch_size, seq_len)</span></span>
<span class="line"><span style="color:#24292E;">        inputs </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.embedding(inputs)</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># 过了self.embdding之后，inputs.shape = (batch_size, seq_len, embedding_dim)</span></span>
<span class="line"><span style="color:#24292E;">        x, _ </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.LSTM(inputs)</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># x.shape = (batch_size, seq_len, hidden_size)</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># 取用 LSTM 最后一个的 hidden state</span></span>
<span class="line"><span style="color:#24292E;">        x </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> x[:, </span><span style="color:#D73A49;">-</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">, :]</span></span>
<span class="line"><span style="color:#24292E;">        x </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.classifier(x)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">return</span><span style="color:#24292E;"> x</span></span></code></pre></div><h3 id="训练模型" tabindex="-1"><strong>训练模型</strong> <a class="header-anchor" href="#训练模型" aria-label="Permalink to &quot;**训练模型**&quot;">​</a></h3><ul><li>首先定义需要的组件，这里损失采用交叉熵损失，优化器采用 Adam</li></ul><div class="language-Python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">Python</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#E1E4E8;">model </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> LSTMModel(</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#FFAB70;">vocab_size</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">30000</span><span style="color:#E1E4E8;">,   </span><span style="color:#6A737D;"># vocab_size为词表大小</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#FFAB70;">embedding_dim</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">300</span><span style="color:#E1E4E8;">,</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#FFAB70;">hidden_dim</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">256</span><span style="color:#E1E4E8;">,</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#FFAB70;">num_layers</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">1</span><span style="color:#E1E4E8;">,</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#FFAB70;">dropout</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">0.1</span><span style="color:#E1E4E8;">,</span></span>
<span class="line"><span style="color:#E1E4E8;">).cuda()    </span><span style="color:#6A737D;"># 将模型移入GPU，只有用GPU时才需要.cuda()</span></span>
<span class="line"><span style="color:#6A737D;"># 定义损失函数和优化器</span></span>
<span class="line"><span style="color:#E1E4E8;">criterion </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> torch.nn.CrossEntropyLoss()</span></span>
<span class="line"><span style="color:#E1E4E8;">optimizer </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> torch.optim.Adam(model.parameters(), </span><span style="color:#FFAB70;">lr</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">0.001</span><span style="color:#E1E4E8;">)</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292E;">model </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> LSTMModel(</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#E36209;">vocab_size</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">30000</span><span style="color:#24292E;">,   </span><span style="color:#6A737D;"># vocab_size为词表大小</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#E36209;">embedding_dim</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">300</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#E36209;">hidden_dim</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">256</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#E36209;">num_layers</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#E36209;">dropout</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">0.1</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">).cuda()    </span><span style="color:#6A737D;"># 将模型移入GPU，只有用GPU时才需要.cuda()</span></span>
<span class="line"><span style="color:#6A737D;"># 定义损失函数和优化器</span></span>
<span class="line"><span style="color:#24292E;">criterion </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> torch.nn.CrossEntropyLoss()</span></span>
<span class="line"><span style="color:#24292E;">optimizer </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> torch.optim.Adam(model.parameters(), </span><span style="color:#E36209;">lr</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">0.001</span><span style="color:#24292E;">)</span></span></code></pre></div><ul><li>接下来就是如何读取数据，并组成 batch 的数据，需要用到上文的<code>CustomDataset()</code></li></ul><div class="language-Python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">Python</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#E1E4E8;">train_dataset </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> CustomDataset(texts_train, labels_train)</span></span>
<span class="line"><span style="color:#E1E4E8;">train_loader </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> torch.utils.data.DataLoader(</span><span style="color:#FFAB70;">dataset</span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;">train_dataset,</span></span>
<span class="line"><span style="color:#E1E4E8;">     </span><span style="color:#FFAB70;">batch_size</span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;">batch_size, </span><span style="color:#FFAB70;">shuffle</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">True</span><span style="color:#E1E4E8;">)</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292E;">train_dataset </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> CustomDataset(texts_train, labels_train)</span></span>
<span class="line"><span style="color:#24292E;">train_loader </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> torch.utils.data.DataLoader(</span><span style="color:#E36209;">dataset</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">train_dataset,</span></span>
<span class="line"><span style="color:#24292E;">     </span><span style="color:#E36209;">batch_size</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">batch_size, </span><span style="color:#E36209;">shuffle</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">True</span><span style="color:#24292E;">)</span></span></code></pre></div><ul><li>然后就可以开始训练了</li></ul><div class="language-Python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">Python</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#F97583;">for</span><span style="color:#E1E4E8;"> epoch </span><span style="color:#F97583;">in</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">range</span><span style="color:#E1E4E8;">(num_epochs):</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#F97583;">for</span><span style="color:#E1E4E8;"> inputs, labels </span><span style="color:#F97583;">in</span><span style="color:#E1E4E8;"> train_loader:</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#6A737D;"># 将tensor移入GPU</span></span>
<span class="line"><span style="color:#E1E4E8;">        inputs </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> inputs.cuda()</span></span>
<span class="line"><span style="color:#E1E4E8;">        labels </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> labels.cuda()</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span></span>
<span class="line"><span style="color:#E1E4E8;">        optimizer.zero_grad()   </span><span style="color:#6A737D;"># 将上一次迭代的梯度清凉</span></span>
<span class="line"><span style="color:#E1E4E8;">        outputs </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> model(inputs)   </span><span style="color:#6A737D;"># 前向传播</span></span>
<span class="line"><span style="color:#E1E4E8;">        loss </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> criterion(outputs, labels)   </span><span style="color:#6A737D;"># 计算损失</span></span>
<span class="line"><span style="color:#E1E4E8;">        loss.backward()    </span><span style="color:#6A737D;"># 反向传播，获得梯度</span></span>
<span class="line"><span style="color:#E1E4E8;">        optimizer.step()    </span><span style="color:#6A737D;"># 通过梯度，进行参数更新</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span></span>
<span class="line"><span style="color:#6A737D;"># 训练完毕，保存模型</span></span>
<span class="line"><span style="color:#E1E4E8;">torch.save(model, </span><span style="color:#9ECBFF;">&quot;./model.pt&quot;</span><span style="color:#E1E4E8;">)</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#D73A49;">for</span><span style="color:#24292E;"> epoch </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">range</span><span style="color:#24292E;">(num_epochs):</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">for</span><span style="color:#24292E;"> inputs, labels </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> train_loader:</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># 将tensor移入GPU</span></span>
<span class="line"><span style="color:#24292E;">        inputs </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> inputs.cuda()</span></span>
<span class="line"><span style="color:#24292E;">        labels </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> labels.cuda()</span></span>
<span class="line"><span style="color:#24292E;">        </span></span>
<span class="line"><span style="color:#24292E;">        optimizer.zero_grad()   </span><span style="color:#6A737D;"># 将上一次迭代的梯度清凉</span></span>
<span class="line"><span style="color:#24292E;">        outputs </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> model(inputs)   </span><span style="color:#6A737D;"># 前向传播</span></span>
<span class="line"><span style="color:#24292E;">        loss </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> criterion(outputs, labels)   </span><span style="color:#6A737D;"># 计算损失</span></span>
<span class="line"><span style="color:#24292E;">        loss.backward()    </span><span style="color:#6A737D;"># 反向传播，获得梯度</span></span>
<span class="line"><span style="color:#24292E;">        optimizer.step()    </span><span style="color:#6A737D;"># 通过梯度，进行参数更新</span></span>
<span class="line"><span style="color:#24292E;">        </span></span>
<span class="line"><span style="color:#6A737D;"># 训练完毕，保存模型</span></span>
<span class="line"><span style="color:#24292E;">torch.save(model, </span><span style="color:#032F62;">&quot;./model.pt&quot;</span><span style="color:#24292E;">)</span></span></code></pre></div><h3 id="评估模型" tabindex="-1"><strong>评估模型</strong> <a class="header-anchor" href="#评估模型" aria-label="Permalink to &quot;**评估模型**&quot;">​</a></h3><ul><li>评估模型，我们还需要划分出一个验证/测试集，并且同样建立<code>DataLoader()</code>，假设为<code>val_loader</code></li></ul><div class="language-Python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">Python</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#6A737D;"># 加载模型</span></span>
<span class="line"><span style="color:#E1E4E8;">model </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> torch.load(</span><span style="color:#9ECBFF;">&quot;./model.pt&quot;</span><span style="color:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F97583;">for</span><span style="color:#E1E4E8;"> inputs, labels </span><span style="color:#F97583;">in</span><span style="color:#E1E4E8;"> val_loader:</span></span>
<span class="line"><span style="color:#E1E4E8;">    outputs </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> model(inputs)</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># 现在的outputs为一个batch的logits，并且shape=(batch_size, 2)</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># 请你通过这个outputs矩阵，结合你所挑选的模型评估指标（如准确率），对模型进行评估</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># 请自行实现</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#6A737D;"># 加载模型</span></span>
<span class="line"><span style="color:#24292E;">model </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> torch.load(</span><span style="color:#032F62;">&quot;./model.pt&quot;</span><span style="color:#24292E;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D73A49;">for</span><span style="color:#24292E;"> inputs, labels </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> val_loader:</span></span>
<span class="line"><span style="color:#24292E;">    outputs </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> model(inputs)</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># 现在的outputs为一个batch的logits，并且shape=(batch_size, 2)</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># 请你通过这个outputs矩阵，结合你所挑选的模型评估指标（如准确率），对模型进行评估</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># 请自行实现</span></span></code></pre></div><p><strong>注意</strong>，<strong>上述均只是一个示例，实际在完成本题过程中，需要根据具体任务和数据进行相应的调整和修改。</strong></p><h2 id="思考" tabindex="-1">思考 <a class="header-anchor" href="#思考" aria-label="Permalink to &quot;思考&quot;">​</a></h2><ol><li>你使用的是什么损失函数？请简单介绍这个损失函数，如果有概率论基础并了解最大似然的同学，请尝试推导出损失函数的数学形式。</li><li>在文本分类任务中可能会面临过拟合问题，尤其是当训练数据较少时，可以采用哪些常见的防止过拟合的方法。</li><li>反向传播是一种用于训练神经网络模型的算法，通过计算损失函数对模型参数的梯度，然后利用梯度下降法更新模型参数。请思考并简单推导一下<strong>你所用的这个模型的</strong>反向传播公式。</li><li>在 LSTM 中，输入门、遗忘门和输出门是如何实现其功能的。</li></ol><h2 id="回答要求" tabindex="-1">回答要求 <a class="header-anchor" href="#回答要求" aria-label="Permalink to &quot;回答要求&quot;">​</a></h2><ol><li>处理数据、训练和测试的代码，并大致解释你的代码；</li><li>代码运行结果截图和训练过程中，损失和<strong>评估指标</strong>（<strong>评估指标不限，如准确率</strong>）的变化图像，并在最后使用你所划分的测试集和你选择的评估指标评估模型结果；</li><li>必要的注释说明及良好的代码规范；</li><li>实现思路和学到的知识点。</li></ol><h2 id="本题提交方式" tabindex="-1">本题提交方式 <a class="header-anchor" href="#本题提交方式" aria-label="Permalink to &quot;本题提交方式&quot;">​</a></h2><blockquote><p>收件邮箱：glimmer401@outlook.com</p><p>主题格式：学号-姓名-考核-机器学习-03</p><p>主题示例：2024091202014-张三-考核-机器学习-03</p></blockquote><blockquote><p>出题人QQ：674940575</p><p>出题人邮箱：<a href="mailto:674940575@qq.com" target="_blank" rel="noreferrer">674940575@qq.com</a></p></blockquote></div></div></main><footer class="VPDocFooter" data-v-6b87e69f data-v-ef5dee53><!--[--><!--]--><!----><nav class="prev-next" data-v-ef5dee53><div class="pager" data-v-ef5dee53><a class="pager-link prev" href="/glimmerRecruit/md/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%96%B9%E5%90%91-02%EF%BC%9A%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E5%AE%9E%E8%B7%B5.html" data-v-ef5dee53><span class="desc" data-v-ef5dee53>Previous page</span><span class="title" data-v-ef5dee53>机器学习方向-02：梯度下降实践</span></a></div><div class="pager" data-v-ef5dee53><a class="pager-link next" href="/glimmerRecruit/md/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%96%B9%E5%90%91-04%EF%BC%9A%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8BGPT.html" data-v-ef5dee53><span class="desc" data-v-ef5dee53>Next page</span><span class="title" data-v-ef5dee53>机器学习方向-04：大语言模型GPT</span></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><!----><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"md_日常基础_日常-06：代码管理.md\":\"c9cc08bb\",\"md_前端_t3-开辟找到微光娘的道路-css.md\":\"21fdf222\",\"md_提示.md\":\"8b99f888\",\"md_机器学习_机器学习方向-01：入门理论基础.md\":\"56b11e99\",\"md_c语言_c project- 00 manual.md\":\"658107a0\",\"md_日常基础_日常-07：loafer想打派(网络).md\":\"90751bb2\",\"md_后端_后端综合数据库出题.md\":\"336246a5\",\"md_c语言_c basis-04 赢不了的游戏.md\":\"f8bdf164\",\"md_c语言_c basis-01 hello_world!.md\":\"a4fd9a53\",\"md_后端_后端综合项目出题.md\":\"83184e63\",\"md_前端_t1-寻找微光娘-网页html元素修改.md\":\"a4e2d7f5\",\"md_前端_前端-04 初识框架.md\":\"26e808e4\",\"md_后端_java01.md\":\"43a37c73\",\"md_后端_go语言基础-level1.md\":\"6f1ef744\",\"md_c语言_c basis-03 神秘密文.md\":\"45240556\",\"md_前端_t5-总算见到你了，微光娘——制作blog.md\":\"3acd7346\",\"md_qa.md\":\"9bbc9056\",\"md_c语言_c 进阶-动态内存分配器.md\":\"e8bd5bdc\",\"md_日常基础_日常-01：什么是计算机？.md\":\"f221fa0d\",\"md_c语言_c project-02 management and testing.md\":\"a70ab372\",\"md_日常基础_日常-04：ide编程前的准备.md\":\"b606c506\",\"md_日常基础_日常-03：数据的表示.md\":\"f12311eb\",\"md_c语言_index.md\":\"a8bc21bd\",\"md_机器学习_机器学习方向-03：文本分类.md\":\"73aa9c44\",\"md_前端_index.md\":\"dd85aa40\",\"md_招新说明.md\":\"f9b1ea63\",\"md_c语言_c project-01  stack.md\":\"1d452211\",\"md_日常基础_index.md\":\"778ac52b\",\"md_前端_t2-搜集微光娘足迹-网站在你电脑里存了什么呢.md\":\"5ef15d16\",\"md_方向简介_其他渠道招新说明.md\":\"83a30e86\",\"md_日常基础_日常-02：markdown.md\":\"bfa8366f\",\"md_c语言_c project-03 the last.md\":\"094f54cd\",\"md_后端_index.md\":\"af2b1563\",\"index.md\":\"cf4f0776\",\"md_机器学习_index.md\":\"ec5d4d59\",\"md_日常基础_日常-05：了解linux.md\":\"f5d79ea6\",\"md_c语言_c basis-02 来邂逅语句吧.md\":\"8cef72a6\",\"md_后端_java03.md\":\"cd011e11\",\"md_后端_java02.md\":\"22f9c71d\",\"md_后端_go语言基础-level0.md\":\"980bda41\",\"md_机器学习_机器学习方向-02：梯度下降实践.md\":\"cc4c6e5f\",\"md_机器学习_机器学习方向-04：大语言模型gpt.md\":\"62a7f54e\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"zh-CN\",\"dir\":\"ltr\",\"title\":\"2024招新\",\"description\":\"A VitePress site\",\"base\":\"/glimmerRecruit/\",\"head\":[],\"appearance\":true,\"themeConfig\":{\"siteTitle\":\"微光工作室\",\"logo\":\"/image/favicon.png\",\"nav\":[{\"text\":\"招新说明\",\"link\":\"/md/招新说明.md\"},{\"text\":\"日常基础\",\"activeMatch\":\"/md/日常基础/\",\"items\":[{\"text\":\"日常-01：什么是计算机？\",\"link\":\"/md/日常基础/日常-01：什么是计算机？.md\"},{\"text\":\"日常-02：markdown\",\"link\":\"/md/日常基础/日常-02：markdown.md\"},{\"text\":\"日常-03：数据的表示\",\"link\":\"/md/日常基础/日常-03：数据的表示.md\"},{\"text\":\"日常-04：IDE编程前的准备\",\"link\":\"/md/日常基础/日常-04：IDE编程前的准备.md\"},{\"text\":\"日常-05：了解linux\",\"link\":\"/md/日常基础/日常-05：了解linux.md\"},{\"text\":\"日常-06：代码管理\",\"link\":\"/md/日常基础/日常-06：代码管理.md\"},{\"text\":\"日常-07：loafer想打派(网络)\",\"link\":\"/md/日常基础/日常-07：loafer想打派(网络).md\"}]},{\"text\":\"C语言\",\"items\":[{\"text\":\"C语言简介\",\"link\":\"/md/C语言/\"},{\"text\":\"C基础\",\"items\":[{\"text\":\"C Basis-01 Hello,world!\",\"link\":\"/md/C语言/C Basis-01 Hello,world!.md\"},{\"text\":\"C Basis-02 来邂逅语句吧\",\"link\":\"/md/C语言/C Basis-02 来邂逅语句吧.md\"},{\"text\":\"C Basis-03 神秘密文\",\"link\":\"/md/C语言/C Basis-03 神秘密文.md\"},{\"text\":\"C Basis-04 赢不了的游戏\",\"link\":\"/md/C语言/C Basis-04 赢不了的游戏.md\"}]},{\"text\":\"C项目\",\"items\":[{\"text\":\"C Project- 00 Manual\",\"link\":\"/md/C语言/C Project- 00 Manual.md\"},{\"text\":\"C Project-01  Stack\",\"link\":\"/md/C语言/C Project-01  Stack.md\"},{\"text\":\"C project-02 Management and Testing\",\"link\":\"/md/C语言/C project-02 Management and Testing.md\"},{\"text\":\"C project-03 The Last\",\"link\":\"/md/C语言/C project-03 The Last.md\"}]},{\"text\":\"C进阶\",\"items\":[{\"text\":\"C 进阶-动态内存分配器\",\"link\":\"/md/C语言/C 进阶-动态内存分配器.md\"}]}]},{\"text\":\"前端\",\"items\":[{\"text\":\"前端简介\",\"link\":\"/md/前端/\"},{\"text\":\"T1-寻找微光娘-网页html元素修改\",\"link\":\"/md/前端/T1-寻找微光娘-网页html元素修改.md\"},{\"text\":\"T2-搜集微光娘足迹-网站在你电脑里存了什么呢\",\"link\":\"/md/前端/T2-搜集微光娘足迹-网站在你电脑里存了什么呢.md\"},{\"text\":\"T3-开辟找到微光娘的道路-CSS\",\"link\":\"/md/前端/T3-开辟找到微光娘的道路-CSS.md\"},{\"text\":\"前端-04 初识框架\",\"link\":\"/md/前端/前端-04 初识框架.md\"},{\"text\":\"T5-总算见到你了，微光娘——制作blog\",\"link\":\"/md/前端/T5-总算见到你了，微光娘——制作blog.md\"}]},{\"text\":\"后端\",\"items\":[{\"text\":\"后端简介\",\"link\":\"/md/后端/\"},{\"text\":\"JAVA\",\"items\":[{\"text\":\"Java-01：基础\",\"link\":\"/md/后端/Java01.md\"},{\"text\":\"Java-02：语言特性\",\"link\":\"/md/后端/Java02.md\"},{\"text\":\"Java-03：异常，网络\",\"link\":\"/md/后端/Java03.md\"}]},{\"text\":\"GO\",\"items\":[{\"text\":\"GO-01：level0\",\"link\":\"/md/后端/Go语言基础-level0.md\"},{\"text\":\"GO-02：level1\",\"link\":\"/md/后端/Go语言基础-level1.md\"}]},{\"text\":\"后端综合\",\"items\":[{\"text\":\"综合项目-数据库\",\"link\":\"/md/后端/后端综合数据库出题.md\"},{\"text\":\"综合项目-项目实践\",\"link\":\"/md/后端/后端综合项目出题.md\"}]}]},{\"text\":\"机器学习\",\"items\":[{\"text\":\"机器学习简介\",\"link\":\"/md/机器学习/\"},{\"text\":\"机器学习方向-01：入门理论基础\",\"link\":\"/md/机器学习/机器学习方向-01：入门理论基础.md\"},{\"text\":\"机器学习方向-02：梯度下降实践\",\"link\":\"/md/机器学习/机器学习方向-02：梯度下降实践.md\"},{\"text\":\"机器学习方向-03：文本分类\",\"link\":\"/md/机器学习/机器学习方向-03：文本分类\"},{\"text\":\"机器学习方向-04：大语言模型GPT\",\"link\":\"/md/机器学习/机器学习方向-04：大语言模型GPT\"}]},{\"text\":\"光点计划\",\"link\":\"http://lab.glimmer.org.cn\"}],\"sidebar\":{\"/md/日常基础/\":[{\"text\":\"日常基础\",\"items\":[{\"text\":\"日常-01：什么是计算机？\",\"link\":\"/md/日常基础/日常-01：什么是计算机？.md\"},{\"text\":\"日常-02：markdown\",\"link\":\"/md/日常基础/日常-02：markdown.md\"},{\"text\":\"日常-03：数据的表示\",\"link\":\"/md/日常基础/日常-03：数据的表示.md\"},{\"text\":\"日常-04：IDE编程前的准备\",\"link\":\"/md/日常基础/日常-04：IDE编程前的准备.md\"},{\"text\":\"日常-05：了解linux\",\"link\":\"/md/日常基础/日常-05：了解linux.md\"},{\"text\":\"日常-06：代码管理\",\"link\":\"/md/日常基础/日常-06：代码管理.md\"},{\"text\":\"日常-07：loafer想打派(网络)\",\"link\":\"/md/日常基础/日常-07：loafer想打派(网络)\"}]}],\"/md/C语言/\":[{\"text\":\"C语言\",\"items\":[{\"text\":\"C语言简介\",\"link\":\"/md/C语言/\"},{\"text\":\"C基础\",\"items\":[{\"text\":\"C Basis-01 Hello,world!\",\"link\":\"/md/C语言/C Basis-01 Hello,world!.md\"},{\"text\":\"C Basis-02 来邂逅语句吧\",\"link\":\"/md/C语言/C Basis-02 来邂逅语句吧.md\"},{\"text\":\"C Basis-03 神秘密文\",\"link\":\"/md/C语言/C Basis-03 神秘密文.md\"},{\"text\":\"C Basis-04 赢不了的游戏\",\"link\":\"/md/C语言/C Basis-04 赢不了的游戏.md\"}]},{\"text\":\"C项目\",\"items\":[{\"text\":\"C Project- 00 Manual\",\"link\":\"/md/C语言/C Project- 00 Manual.md\"},{\"text\":\"C Project-01  Stack\",\"link\":\"/md/C语言/C Project-01  Stack.md\"},{\"text\":\"C project-02 Management and Testing\",\"link\":\"/md/C语言/C project-02 Management and Testing.md\"},{\"text\":\"C project-03 The Last\",\"link\":\"/md/C语言/C project-03 The Last.md\"}]},{\"text\":\"C进阶\",\"items\":[{\"text\":\"C 进阶-动态内存分配器\",\"link\":\"/md/C语言/C 进阶-动态内存分配器.md\"}]}]}],\"/md/前端/\":[{\"text\":\"前端\",\"link\":\"/md/前端/\",\"items\":[{\"text\":\"T1-寻找微光娘-网页html元素修改\",\"link\":\"/md/前端/T1-寻找微光娘-网页html元素修改.md\"},{\"text\":\"T2-搜集微光娘足迹-网站在你电脑里存了什么呢\",\"link\":\"/md/前端/T2-搜集微光娘足迹-网站在你电脑里存了什么呢.md\"},{\"text\":\"T3-开辟找到微光娘的道路-CSS\",\"link\":\"/md/前端/T3-开辟找到微光娘的道路-CSS.md\"},{\"text\":\"前端-04 初识框架\",\"link\":\"/md/前端/前端-04 初识框架.md\"},{\"text\":\"T5-总算见到你了，微光娘——制作blog\",\"link\":\"/md/前端/T5-总算见到你了，微光娘——制作blog.md\"}]}],\"/md/后端/\":[{\"text\":\"后端\",\"items\":[{\"text\":\"后端简介\",\"link\":\"/md/后端/\"},{\"text\":\"JAVA\",\"items\":[{\"text\":\"Java-01：基础\",\"link\":\"/md/后端/Java01.md\"},{\"text\":\"Java-02：语言特性\",\"link\":\"/md/后端/Java02.md\"},{\"text\":\"Java-03：异常，网络\",\"link\":\"/md/后端/Java03.md\"}]},{\"text\":\"GO\",\"items\":[{\"text\":\"GO-01：level0\",\"link\":\"/md/后端/Go语言基础-level0.md\"},{\"text\":\"GO-02：level1\",\"link\":\"/md/后端/Go语言基础-level1.md\"}]},{\"text\":\"后端综合\",\"items\":[{\"text\":\"综合项目-数据库\",\"link\":\"/md/后端/后端综合数据库出题.md\"},{\"text\":\"综合项目-项目实践\",\"link\":\"/md/后端/后端综合项目出题.md\"}]}]}],\"/md/机器学习/\":[{\"text\":\"机器学习\",\"link\":\"/md/机器学习/\",\"items\":[{\"text\":\"机器学习方向-01：入门理论基础\",\"link\":\"/md/机器学习/机器学习方向-01：入门理论基础.md\"},{\"text\":\"机器学习方向-02：梯度下降实践\",\"link\":\"/md/机器学习/机器学习方向-02：梯度下降实践.md\"},{\"text\":\"机器学习方向-03：文本分类\",\"link\":\"/md/机器学习/机器学习方向-03：文本分类\"},{\"text\":\"机器学习方向-04：大语言模型GPT\",\"link\":\"/md/机器学习/机器学习方向-04：大语言模型GPT\"}]}]},\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://www.4399.com/\"}]},\"locales\":{},\"scrollOffset\":90,\"cleanUrls\":false}");</script>
    
  </body>
</html>